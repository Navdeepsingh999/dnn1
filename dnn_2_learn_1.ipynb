{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization\n",
    "ax = sns.countplot(data['target'],label='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
       "0       17.99        10.38         122.80    1001.0         0.11840   \n",
       "1       20.57        17.77         132.90    1326.0         0.08474   \n",
       "2       19.69        21.25         130.00    1203.0         0.10960   \n",
       "3       11.42        20.38          77.58     386.1         0.14250   \n",
       "4       20.29        14.34         135.10    1297.0         0.10030   \n",
       "\n",
       "  mean compactness mean concavity mean concave points mean symmetry  \\\n",
       "0          0.27760         0.3001             0.14710        0.2419   \n",
       "1          0.07864         0.0869             0.07017        0.1812   \n",
       "2          0.15990         0.1974             0.12790        0.2069   \n",
       "3          0.28390         0.2414             0.10520        0.2597   \n",
       "4          0.13280         0.1980             0.10430        0.1809   \n",
       "\n",
       "  mean fractal dimension radius error texture error perimeter error  \\\n",
       "0                0.07871       1.0950        0.9053           8.589   \n",
       "1                0.05667       0.5435        0.7339           3.398   \n",
       "2                0.05999       0.7456        0.7869           4.585   \n",
       "3                0.09744       0.4956        1.1560           3.445   \n",
       "4                0.05883       0.7572        0.7813           5.438   \n",
       "\n",
       "  area error smoothness error compactness error concavity error  \\\n",
       "0     153.40         0.006399           0.04904         0.05373   \n",
       "1      74.08         0.005225           0.01308         0.01860   \n",
       "2      94.03         0.006150           0.04006         0.03832   \n",
       "3      27.23         0.009110           0.07458         0.05661   \n",
       "4      94.44         0.011490           0.02461         0.05688   \n",
       "\n",
       "  concave points error symmetry error fractal dimension error worst radius  \\\n",
       "0              0.01587        0.03003                0.006193        25.38   \n",
       "1              0.01340        0.01389                0.003532        24.99   \n",
       "2              0.02058        0.02250                0.004571        23.57   \n",
       "3              0.01867        0.05963                0.009208        14.91   \n",
       "4              0.01885        0.01756                0.005115        22.54   \n",
       "\n",
       "  worst texture worst perimeter worst area worst smoothness worst compactness  \\\n",
       "0         17.33          184.60     2019.0           0.1622            0.6656   \n",
       "1         23.41          158.80     1956.0           0.1238            0.1866   \n",
       "2         25.53          152.50     1709.0           0.1444            0.4245   \n",
       "3         26.50           98.87      567.7           0.2098            0.8663   \n",
       "4         16.67          152.20     1575.0           0.1374            0.2050   \n",
       "\n",
       "  worst concavity worst concave points worst symmetry worst fractal dimension  \\\n",
       "0          0.7119               0.2654         0.4601                 0.11890   \n",
       "1          0.2416               0.1860         0.2750                 0.08902   \n",
       "2          0.4504               0.2430         0.3613                 0.08758   \n",
       "3          0.6869               0.2575         0.6638                 0.17300   \n",
       "4          0.4000               0.1625         0.2364                 0.07678   \n",
       "\n",
       "  target  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.c_[data.data,data.target],columns=[list(data.feature_names)+['target']])\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.keys()\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.fit_transform(X_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making first neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: making first input layer and first hidden layer ;\n",
    "classifier.add(Dense(units=16,kernel_initializer='uniform',input_shape=(30,),activation ='relu'))\n",
    "# for adding layer in classifier we use add method and for making layer we use Dense function ;\n",
    "# units = number of neurons in layers ;\n",
    "# input_dim = are the independent variable quantity from the data ;\n",
    "# kernel_initializer = how to initialize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: second hidden layer ;\n",
    "classifier.add(Dense(units = 16, activation = 'relu',))\n",
    "\n",
    "# 3: output layer ;\n",
    "classifier.add(Dense(units= 1,  activation = 'sigmoid',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "# adam : is just like gradient descent ; it is the wayor algorithm to adjusting weights just like stochastic gradient descent ;\n",
    "# loss : to calculate the loss ; if output type is multiple then we use categorical_crossentropy ; when binary then we use binary_crossentropy ;\n",
    "# metrics : show accuracy while going through different epoch(iteration) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.4637\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.8374\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.9385\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.9473\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.9473\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.9473\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.9495\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.9516\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.9560\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.9560\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.9560\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.9604\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.9626\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.9626\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9648\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9648\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9648\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9670\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9736\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9736\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.9736\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9736\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9714\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9736\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9736\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9758\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9802\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9824\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9824\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0864 - accuracy: 0.9846\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9846\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9846\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9846\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9846\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9846\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9846\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9868\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9868\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9868\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9868\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9868\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9868\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9868\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9868\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9868\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9868\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9868\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9868\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9868\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9868\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9868\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 0.9890\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9890\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9890\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9890\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9890\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9890\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9890\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9890\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9890\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9890\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9890\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9890\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9890\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9890\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9890\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9890\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9890\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.97 - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9890\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9890\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9912\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9912\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9912\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9912\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9912\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9912\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9912\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9912\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9912\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9912\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9912\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9912\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9912\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9912\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9912\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9912\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9934\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9934\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9934\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9934\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9934\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9934\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9934\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9934\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9934\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9934\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9934\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f9b4832710>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train,batch_size=100,epochs=100) # 100 quantity train at a time ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred= (y_pred >0.5)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34,  2],\n",
       "       [ 7, 71]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f9b495b2e8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
